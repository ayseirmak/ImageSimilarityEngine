DEFINITION="**_With the Image Similarity Engine, you can find the most matched image(s)  from the dataset for your selected image_**"
PURPOSE = "On this platform, you can find the images that are most similar to the image you selected from the datasets you have uploaded or the datasets you will upload."
STAGES= "1. Upload the image you want to find similar images in the dataset\n2. If you want the selected image to be searched in your dataset, load your dataset. If you want the selected image to be found among the pre-loaded datasets on the platform, check the one that interests you from the pre-loaded datasets.\n3. Determine how many images similar to the one you selected will be found in the dataset\n4. Select the embedding methods, and distance metrics units to be used in search algorithms to find similarities between images.\n5. Press the submit button to start the process.\n6. If you have uploaded your dataset to the platform, our model will be trained according to your dataset. You can see the default parameters used by the model from the redirected page after the Submit process and you can change these parameters as you wish.\n       If you want to operate on existing datasets, similar images will be reflected on the screen after submission."
UT="By using the autoencoder architecture, compressed feature matrices of the selected image and the images in the dataset are created. Then, according to the embedding method you choose, the extracted feature matrices are converted to one-dimensional vectors with flatten or global max pooling layer.  These one-dimensional representation vectors of images in the dataset are placed in multidimensional space. According to the distance metric values you choose for use supervised KNN, algorithm, the vectors that are closest to the representation vector of the selected image are determined. At last, images of those vectors are projected onto the screen."
FTC="1. If you upload your own dataset to the platform, this process may take a long time as the model will be trained. You can see the default parameters of our autoencoder model and the performance graphs according to the datasets in **_MODEL_** section.\n2. Depending on the image and dataset you choose, different results can be obtained depending on embedding methods and distance units used.\n3. You can find the performances of the previously loaded datasets according to the algorithms and distance units used in **_Dataset_** section."